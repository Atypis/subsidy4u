# Subsidy4U - German FÃ¶rdermittel Assistant

AI-powered assistant to help German companies and startups navigate 2,000+ subsidy programs (FÃ¶rdermittel).

## ğŸ¯ Problem

German companies struggle with the overwhelming landscape of subsidies:
- 2,000+ programs across federal, state, and EU levels
- Complex eligibility requirements
- Fragmented information sources
- Time-consuming manual research

## ğŸ’¡ Solution

An AI assistant that:
1. **Extracts company details** from websites or documents (HR-Auszug)
2. **Filters programs** through conversational guidance
3. **Applies intelligent matching** against eligibility criteria
4. **Visualizes the filtering process** in real-time
5. **Delivers a curated list** of relevant, likely-eligible programs

## ğŸ—ï¸ Architecture

### Split-Screen Interface
- **Left**: Conversational AI assistant (AI SDK v5)
- **Right**: Live visualization of filtering process

### Tech Stack
- **Frontend**: Next.js 15 + AI SDK v5 + TailwindCSS + shadcn/ui
- **Backend**: Supabase (PostgreSQL + pgvector)
- **Deployment**: Vercel + Supabase
- **Data Source**: foerderdatenbank.de (scraped)

## ğŸ“¦ Project Structure

```
subsidy4u/
â”œâ”€â”€ browser-automation-mcp/    # Browser automation MCP server
â”‚   â”œâ”€â”€ src/                   # TypeScript source
â”‚   â”œâ”€â”€ dist/                  # Built JS files
â”‚   â””â”€â”€ docs/                  # Documentation
â”œâ”€â”€ plan.md                    # Complete project plan
â”œâ”€â”€ browser-mcp.md             # MCP server specification
â””â”€â”€ NEXT_STEPS.md             # Implementation roadmap
```

## ğŸ”§ Browser Automation MCP Server

**v1.0.2** - Production-ready browser automation for AI assistants

### Features
- 24 browser automation tools powered by Playwright
- Execute JavaScript for targeted data extraction
- Network inspection to discover hidden APIs
- Auto-pagination for batch scraping
- Response size limits to prevent crashes
- Comprehensive error handling

### Quick Start

```bash
cd browser-automation-mcp
npm install
npx playwright install chromium
npm run build
```

Configure in Claude Desktop:
```json
{
  "mcpServers": {
    "browser-automation": {
      "command": "node",
      "args": ["/path/to/subsidy4u/browser-automation-mcp/dist/index.js"]
    }
  }
}
```

See [browser-automation-mcp/README.md](browser-automation-mcp/README.md) for full documentation.

## ğŸ“‹ Implementation Status

- âœ… **Project planning** - Complete architecture and roadmap
- âœ… **Browser MCP server** - Built and tested
- â³ **Website scraping** - Next phase
- â³ **Database setup** - Supabase schema
- â³ **Frontend** - Next.js + AI SDK v5
- â³ **Deployment** - Vercel hosting

## ğŸš€ Next Steps

1. **Scrape foerderdatenbank.de**
   - Use browser MCP to discover structure
   - Extract all ~2,000 programs with metadata
   - Parse legal requirements and filter attributes

2. **Build database**
   - Design Supabase schema
   - Import scraped data
   - Add vector search for semantic matching

3. **Develop frontend**
   - Implement chat interface
   - Build live filtering visualization
   - Create company info extraction flow

4. **Deploy**
   - Launch on Vercel
   - Set up CI/CD
   - Monitor and iterate

## ğŸ“– Documentation

- [plan.md](plan.md) - Complete project plan with architecture
- [browser-mcp.md](browser-mcp.md) - MCP server specification
- [NEXT_STEPS.md](NEXT_STEPS.md) - Implementation roadmap
- [browser-automation-mcp/BEST_PRACTICES.md](browser-automation-mcp/BEST_PRACTICES.md) - Scraping guide

## ğŸ¤ Contributing

This is a personal project, but feedback and suggestions are welcome!

## ğŸ“„ License

MIT

---

**Current Version**: Browser MCP v1.0.2  
**Status**: Development - MCP Server Complete  
**Repository**: https://github.com/Atypis/subsidy4u
